{"name":"Fractal","tagline":"Flexible Recurrent ArChitecture TrAining Library","body":"### Introduction\r\n\r\nFractal is a C++ library for online training and testing of unidirectional RNNs. The library is written in C++ and CUDA and runs on NVIDIA GPUs.\r\n\r\nFractal supports very flexible network design by adapting a graph-based layered structure. Complex networks such as LSTM can be represented by connecting basic layers.\r\n\r\nThe main purpose of Fractal is to train unidirectional RNNs for online applications (e.g. continuously running RNNs). Therefore, the training is basically performed on infinite training streams, not finite sequences. These training streams may be naturally infinite, or can be artificially generated by concatenating training sequences. The objective is to make the resulting RNN run on a infinite input stream.\r\n\r\nThe graph-based generalization of RNNs and parallelization algorithm is based on [1]. The online CTC algorithm is described in [2].\r\n\r\n### License\r\nApache License 2.0\r\n\r\n### Author\r\n\r\nFractal is written by Kyuyeon Hwang during his Ph.D. at Signal Processing Systems Lab., Seoul National University (advisor: Prof. Wonyong Sung).\r\n\r\n### References\r\n\r\n[1] Kyuyeon Hwang and Wonyong Sung. \"Single stream parallelization of generalized LSTM-like RNNs on a GPU.\" _ICASSP 2015_.\r\n\r\n[2] Kyuyeon Hwang and Wonyong Sung. \"Online Sequence Training of Recurrent Neural Networks with Connectionist Temporal Classification.\" _arXiv preprint arXiv:1511.06841_ (2015).","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}